#!/home/sbsuser/.edm/envs/python3/bin/python3

import json
import os
import sys
from subprocess import Popen, PIPE

#merge the resulting fastq and summary files from Guppy or Albacore basecalling
#make MinionQC plots for each summary file
#compress the merged fastqs

#barcode names in the LIMS
ONT2LIMS = {
         'barcode01' : 'NB01',
         'barcode02' : 'NB02',
         'barcode03' : 'NB03',
         'barcode04' : 'NB04',
         'barcode05' : 'NB05',
         'barcode06' : 'NB06',
         'barcode07' : 'NB07',
         'barcode08' : 'NB08',
         'barcode09' : 'NB09',
         'barcode10' : 'NB10',
         'barcode11' : 'NB11',
         'barcode12' : 'NB12',
         'barcode13' : 'NB13',
         'barcode14' : 'NB14',
         'barcode15' : 'NB15',
         'barcode16' : 'NB16',
         'barcode17' : 'NB17',
         'barcode18' : 'NB18',
         'barcode19' : 'NB19',
         'barcode20' : 'NB20',
         'barcode21' : 'NB21',
         'barcode22' : 'NB22',
         'barcode23' : 'NB23',
         'barcode24' : 'NB24',
         'unclassified' : 'unclassified'
         }

#use this pigz
pigz = '/apps/PIGZ/2.3.1/bin/pigz'

#look for the RunInfo file generated by the basecaller script
if ( not os.path.isfile('./RunInfo') ) :
   sys.exit( 'File RunInfo not found! Must run basecalling script to generate it.\n')
f= open('./RunInfo','r')
runInfo = json.load(f)
f.close()

#check the barcodes
if ( runInfo['barcoded'] ) :
   cmd =  "lfs find ./scratch -type d -name 'barcode*'  2> /dev/null "
   p = Popen(cmd ,shell=True, stdout=PIPE)
   (output, error) = p.communicate()
   p.wait()
   fout = output.decode().split('\n')[:-1]         
   barcodes = set()
   for iout in fout :
      ibar = iout.split('/')[-1]
      if ( ibar not in ONT2LIMS ) : continue #barcode must be in the LIMS otherwise ignore
      barcodes.add( ibar )

#setup script 
outfile = open('.' + '/post.cmd','w')
outfile.write(
"""#!/bin/bash
# @ output = post.out
# @ error = post.err
# @ total_tasks = 1
# @ cpus_per_task = 4
# @ wall_clock_limit = 02:59:00
""")
outfile.write("# @ initialdir = .\n")
outfile.write("# @ job_name = %s_%s_post\n"%(runInfo['flowcell'],1 ))
outfile.write("\n")
outfile.write("module purge\n")
outfile.write("module load gcc/6.3.0\n")
outfile.write("module load R/3.5.0\n\n")
outfile.write("set -e\n\n")

#merge all the fastq files (exclude 1D2 reads)
if (  runInfo['barcoded'] ) :
   for ibarcode in ( list(barcodes) + ['unclassified'] )  :
      fliName = "%s_%s_%s"%(runInfo['flowcell'],runInfo['runNumber'], ONT2LIMS[ibarcode])
      fastqFile = "%s/%s_%s_%s.fastq"%('.',runInfo['flowcell'],runInfo['runNumber'], ONT2LIMS[ibarcode] )            
      outfile.write("lfs find %s -name '*.fastq'  | grep -v '/1dsq_analysis/' | grep '/%s/' | xargs -i cat {} > %s\n"%('.'+"/scratch/out",ibarcode,fastqFile) )
else :
   fliName = "%s_%s_%s"%(runInfo['flowcell'],runInfo['runNumber'], '0')
   fastqFile = "%s/%s_%s_0.fastq"%('.',runInfo['flowcell'],runInfo['runNumber'])
   outfile.write("lfs find %s -name '*.fastq' |  grep -v '/1dsq_analysis/' | xargs -i cat {} > %s\n"%('.'+"/scratch/out",fastqFile) )

#merge all the fastq files for 1D2 reads
if ( runInfo['chemistry'] == '1D^2' ) :
   if ( not os.path.exists('./1dsq_analysis') ) : os.makedirs('./1dsq_analysis')
   fastqFile = "%s/%s_%s_0.fastq"%('./1dsq_analysis',runInfo['flowcell'],runInfo['runNumber'])
   outfile.write("lfs find %s -name '*.fastq' |  grep '/1dsq_analysis/' | xargs -i cat {} > %s\n"%('.'+"/scratch/out",fastqFile) )

#merge all the sequencing summary files (exclude 1D2 reads) 
if (  runInfo['barcoded'] ) :
   for ibarcode in ( list(barcodes) + ['unclassified'] )  :
      outfile.write("lfs find %s/scratch/out -name 'sequencing_summary.txt' | grep -v '/1dsq_analysis/'  | head -1 | xargs head -1 > %s/sequencing_summary.%s.txt\n"%('.','.', ONT2LIMS[ibarcode]))
      outfile.write("lfs find %s/scratch/out -name 'sequencing_summary.txt' | grep -v '/1dsq_analysis/'  | xargs -i awk \'$20 == \"%s\"\' {}  >> %s/sequencing_summary.%s.txt\n"%('.',ibarcode,'.', ONT2LIMS[ibarcode]))
      #generate MinionQC plots
      outfile.write("Rscript /home/sbsuser/MinION/minion_qc-1.3.0/MinionQC.R -f %s -i %s -o %s/qc_plots/%s\n"%(fliName,'.'+'/sequencing_summary.%s.txt'%ONT2LIMS[ibarcode],'.', ONT2LIMS[ibarcode] ))
else :
   outfile.write("lfs find %s/scratch/out -name 'sequencing_summary.txt' | grep -v '/1dsq_analysis/' | head -1 | xargs head -1 > %s/sequencing_summary.0.txt\n"%('.','.'))
   outfile.write("lfs find %s/scratch/out -name 'sequencing_summary.txt' | grep -v '/1dsq_analysis/' | xargs -i tail -n+2 {}  >> %s/sequencing_summary.0.txt\n"%('.','.'))
   outfile.write("Rscript /home/sbsuser/MinION/minion_qc-1.3.0/MinionQC.R -f %s -i %s -o %s/qc_plots/0\n"%(fliName,'.'+'/sequencing_summary.0.txt','.'))

#merge all the sequencing summary files for 1D2 reads
if ( runInfo['chemistry'] == '1D^2' ) :
   outfile.write("lfs find %s/scratch/out -name 'sequencing*summary.txt' | grep '/1dsq_analysis/' | head -1 | xargs head -1 > %s/sequencing_summary.txt\n"%('.','1dsq_analysis'))
   outfile.write("lfs find %s/scratch/out -name 'sequencing*summary.txt' | grep '/1dsq_analysis/' | xargs -i tail -n+2 {}  >> %s/sequencing_summary.txt\n"%('.','1dsq_analysis'))

#compress all the merged fastq files
outfile.write("%s -p4 *.fastq\n"%pigz)
if ( runInfo['chemistry'] == '1D^2' ) :
   outfile.write("%s -p4 ./1dsq_analysis/*.fastq\n"%pigz)


#touch post done to show we completed successfully 
outfile.write("touch post.done\n\n")
outfile.close()
launch = ['/opt/perf/bin/mnsubmit', '.' + '/post.cmd' ]
p = Popen(launch, stdout=PIPE, stderr=PIPE)
p.wait()
out = p.stdout.read().decode()
err = p.stderr.read().decode()
if ('ERROR' in err) :
   print("!! Error submitting job array to cluster (%s)"%(err))
   raise Exception("Error submitting job array to cluster")
print(out)
